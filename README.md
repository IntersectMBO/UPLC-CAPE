# UPLC-CAPE ğŸš€

**Comparative Artifact Performance Evaluation for UPLC Programs**

A standardized benchmarking framework for measuring and comparing the on-chain performance of UPLC programs generated by different Cardano smart contract compilers.

[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE) [![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CONTRIBUTING.md)

---

## ğŸ¯ Overview

UPLC-CAPE provides a **friendly competition platform** for Cardano compiler authors to:

- ğŸ“Š **Benchmark** their compiler's UPLC output against standardized scenarios
- ğŸ”„ **Compare** performance across different compilers and versions
- ğŸ“ˆ **Track** optimization improvements over time
- ğŸ† **Showcase** efficient implementations to the community

### Why UPLC-CAPE?

Currently, comparing UPLC output from different compilers (Aiken, Plinth, Plutarch, etc.) is ad-hoc and inconsistent. UPLC-CAPE standardizes this process by providing:

- **Consistent benchmarks** - Well-defined computational scenarios
- **Standardized metrics** - CPU units, memory units, script size, term size
- **Reproducible results** - Version-controlled scenarios and submission metadata
- **Community-driven** - Open collaboration between compiler teams

---

## ğŸš€ Quick Start

### Prerequisites

- [Nix](https://nixos.org/download.html) with flakes enabled
- Git

### Installation

```bash
# Clone the repository
git clone https://github.com/your-org/UPLC-CAPE.git
cd UPLC-CAPE

# Enter the development environment
nix develop
# Or if using direnv (recommended)
direnv allow

# Verify installation
cape --help
```

### Your First Benchmark

```bash
# List available benchmarks
cape benchmark list

# View a specific benchmark
cape benchmark fibonacci

# Create a submission for your compiler
cape submission new fibonacci MyCompiler 1.0.0 myhandle
```

---

## ğŸ“‹ Available Benchmarks

| Benchmark | Type | Description | Status |
| --- | --- | --- | --- |
| [Fibonacci](scenarios/fibonacci.md) | Synthetic | Recursive algorithm performance | âœ… Ready |
| Two-Party Escrow | Real-world | Smart contract scenario | ğŸš§ Planned |
| Streaming Payments | Real-world | Payment channel implementation | ğŸš§ Planned |
| Simple DAO Voting | Real-world | Governance mechanism | ğŸš§ Planned |
| Time-locked Staking | Real-world | Staking protocol | ğŸš§ Planned |

---

## ğŸ› ï¸ Usage

### Core Commands

```bash
# Benchmark Management
cape benchmark list                    # List all benchmarks
cape benchmark list fibonacci          # Show specific benchmark details
cape benchmark new my-benchmark        # Create new benchmark

# Submission Management
cape submission list                   # List all submissions
cape submission list fibonacci         # Show submissions for specific benchmark
cape submission new fibonacci Aiken 1.0.8 myhandle  # Create new submission
cape submission validate                # Validate submission files
cape submission validate --all          # Validate all submissions
```

### Interactive Mode

All commands support interactive prompting for missing arguments:

```bash
# These will prompt for missing information
cape benchmark new                     # Prompts for benchmark name
cape submission new                    # Prompts for all required fields
cape submission new fibonacci          # Prompts for compiler, version, handle
```

### Command Help

```bash
cape --help                           # Show main help
cape benchmark --help                 # Show benchmark command help
cape submission new --help            # Show specific subcommand help
```

---

## ğŸ“ Creating a Submission

### 1. Choose a Benchmark

```bash
cape benchmark list
```

### 2. Create Submission Structure

```bash
cape submission new fibonacci MyCompiler 1.0.0 myhandle
```

This creates: `submissions/fibonacci/MyCompiler_1.0.0_myhandle/`

### 3. Add Your UPLC Program

Replace the placeholder with your compiled UPLC:

```bash
# Edit: submissions/fibonacci/MyCompiler_1.0.0_myhandle/fibonacci.uplc
# Your fully-applied UPLC program that computes fibonacci(25)
```

### 4. Measure Performance

Run your UPLC program and fill in the metrics:

```bash
# Edit: submissions/fibonacci/MyCompiler_1.0.0_myhandle/metrics.json
{
  "cpu_units": 185916,
  "memory_units": 592,
  "script_size_bytes": 1234,
  "term_size": 45
}
```

### 5. Validate Your Submission

Before submitting, validate your files against the required schemas:

```bash
# Validate your submission directory
cd submissions/fibonacci/MyCompiler_1.0.0_myhandle/
cape submission validate

# Or validate from project root
cape submission validate submissions/fibonacci/MyCompiler_1.0.0_myhandle/

# Validate specific files if needed
cape submission validate --single metrics.json
cape submission validate --single metadata.json
```

### 6. Update Metadata

```bash
# Edit: submissions/fibonacci/MyCompiler_1.0.0_myhandle/metadata.json
{
  "compiler_name": "MyCompiler",
  "compiler_version": "1.0.0",
  "contributor_handle": "myhandle",
  "submission_date": "2025-01-15",
  "optimization_level": "O2"
}
```

### 7. Document Your Implementation

Edit the README.md with implementation notes, optimization strategies, and any relevant details.

---

## ğŸ—ï¸ Project Structure

```
UPLC-CAPE/
â”œâ”€â”€ scenarios/              # Benchmark definitions
â”‚   â”œâ”€â”€ TEMPLATE/           # Template for new benchmarks
â”‚   â””â”€â”€ fibonacci.md        # Fibonacci benchmark specification
â”œâ”€â”€ submissions/            # Compiler submissions
â”‚   â”œâ”€â”€ TEMPLATE/           # Template for new submissions
â”‚   â””â”€â”€ fibonacci/          # Submissions for fibonacci benchmark
â”‚       â””â”€â”€ Aiken_1.0.8_contributor/  # Example submission
â”œâ”€â”€ scripts/               # CAPE management tools
â”‚   â”œâ”€â”€ cape.sh           # Main CLI tool
â”‚   â””â”€â”€ cape-subcommands/ # Command implementations
â”œâ”€â”€ doc/                  # Documentation
â”‚   â”œâ”€â”€ domain-model.md   # Framework architecture
â”‚   â””â”€â”€ adr/             # Architecture Decision Records
â””â”€â”€ templates/           # File templates
```

---

## ğŸ“Š Metrics Explained

| Metric           | Description                         | Measurement        |
| ---------------- | ----------------------------------- | ------------------ |
| **CPU Units**    | Computational cost for execution    | CEK machine steps  |
| **Memory Units** | Memory consumption during execution | CEK machine memory |
| **Script Size**  | Size of the compiled UPLC script    | Bytes              |
| **Term Size**    | Size of the UPLC term               | AST nodes          |

---

## ğŸ¤ Contributing

We welcome contributions from compiler authors, benchmark designers, and performance researchers!

### Adding a New Benchmark

```bash
# Create benchmark specification
cape benchmark new my-new-benchmark

# Edit the generated file
nano scenarios/my-new-benchmark.md

# Submit a pull request
```

### Adding a Submission

```bash
# Create submission for existing benchmark
cape submission new existing-benchmark MyCompiler 1.0.0 myhandle

# Fill in your UPLC program and metrics
# Submit a pull request
```

### Detailed Guidelines

- ğŸ“– [Contributing Guide](CONTRIBUTING.md) - Detailed contribution process
- ğŸ›ï¸ [Domain Model](doc/domain-model.md) - Framework architecture
- ğŸ“‹ [Templates](templates/) - File templates and examples

When contributing to this project:

1. Enter the development environment: `nix develop`
2. Check existing ADRs to understand current architectural decisions
3. Create an ADR for any significant architectural changes: `adr new "Your Decision"`
4. Follow the established patterns and guidelines documented in the ADRs

---

## ğŸ”§ Development

### Development Environment

This project uses Nix for reproducible development environments:

```bash
# Enter the development shell
nix develop

# Or if using direnv (recommended)
direnv allow

# Available tools:
cape <command>       # CAPE management tool
adr new "Title"      # Create Architecture Decision Record
mmdc -i file.mmd     # Generate diagrams
```

### Testing Commands

```bash
# Test the CLI tool
cape benchmark list
cape submission list

# Run tests (if available)
just test
```

---

## ğŸ“š Documentation

### Architecture Decision Records (ADRs)

This project uses Architecture Decision Records to document important architectural and design decisions. ADRs are managed using [Log4brains](https://github.com/thomvaill/log4brains).

#### ADR Commands

The development environment includes convenient short commands for managing ADRs:

```bash
# Create a new ADR
adr new "My Decision Title"

# Preview ADRs in your browser
adr preview

# Build static documentation site
adr build

# Show help and available commands
adr help
```

#### Single Letter Aliases

For even faster usage, single letter aliases are available:

```bash
adr n "Quick ADR"    # new
adr p               # preview
adr b               # build
adr h               # help
```

#### ADR Workflow

1. **Before making significant decisions**: Check existing ADRs in `doc/adr/`
2. **When making a new decision**: Create an ADR using `adr new "Decision Title"`
3. **Follow the template**: Fill out Context, Decision, and Consequences sections
4. **Review process**: Use `adr preview` to review your ADR in the browser
5. **Commit**: Include the ADR in your pull request with the related changes

#### Current ADRs

- [ADR 0001: Record architecture decisions](doc/adr/0001-record-architecture-decisions.md)
- [ADR 0002: Use Log4brains for ADR management](doc/adr/0002-use-log4brains-for-adr-management.md)

### Additional Documentation

- ğŸ›ï¸ [Domain Model](doc/domain-model.md) - Framework architecture and entities
- ğŸ“‹ [Contributing Guide](CONTRIBUTING.md) - How to contribute
- ğŸ¯ [Project Epic](.md/EPIC.md) - Detailed project description and goals
- ğŸ“– [Benchmark Specifications](scenarios/) - Individual benchmark details

---

## ğŸŒŸ Community

### Get Help

- ğŸ’¬ **Discussions** - Use GitHub Discussions for questions
- ğŸ› **Issues** - Report bugs via GitHub Issues
- ğŸ“§ **Contact** - Reach out to the Plutus Core team

### Compiler Participation

We invite all Cardano compiler teams to participate:

- **Aiken** - Modern smart contract language
- **Plinth** - Reference implementation
- **Plutarch** - High-level eDSL
- **Your Compiler** - Join the friendly competition!

---

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‰ Acknowledgments

- **Plutus Core Team** - Framework infrastructure and reference implementations
- **Compiler Authors** - For participating in the friendly competition
- **Community Contributors** - For benchmark scenarios and improvements

---

## ğŸ“š Resources

- [Log4brains Documentation](https://github.com/thomvaill/log4brains) - ADR tool documentation
- [Architecture Decision Records](http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions) - ADR concept by Michael Nygard

---

<div align="center">

**Ready to benchmark your compiler? ğŸš€**

[Get Started](#-quick-start) Â· [View Benchmarks](#-available-benchmarks) Â· [Join the Community](#-community)

</div>
